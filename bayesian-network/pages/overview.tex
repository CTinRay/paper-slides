
\begin{frame}
\frametitle{Outline}
\tableofcontents
\end{frame}
\section{Introduction}


\begin{frame}
  \frametitle{Abstract}
  \begin{itemize}
  \item RNN learnt by learning distribution of weights.
  \item Better performance on language modeling and image caption generation than original LSTM.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Motivation of Learning Distribution}
  \begin{itemize}
  \item Regularization by prior
    \begin{align*}
      \log P(\theta | D)
      &= \log \frac{P(D | \theta) P(\theta)}{P(D)} \\
      &= \underbrace{\log P(D | \theta)}_{\text{log likelihood}}
        + \underbrace{\log P(\theta)}_{\text{prior}}
        - \underbrace{\log P(D)}_{\text{constant}}
    \end{align*}
    
  \item Expression of uncertainty
  \item (Train an infinite ensemble while only double the number of parameter)
    \begin{equation*}
      P(y | x) = \mathbb{E}_{P(\theta|D)}[P(y|x, w)]
    \end{equation*}
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Variational Approximation}
  \begin{itemize}
  \item Assume that network weights $\theta$ follow a prior distribution $P(\theta)$.
  \item From data $D$, we want to learn 
    \begin{align*}
      P(\theta | D) = \frac{P(D | \theta) P(\theta)}{\int_\theta P(D | \theta) P(\theta) \mathrm{d}\theta }
    \end{align*}
  \item But $\int_\theta P(D | \theta) P(\theta) \mathrm{d}\theta$ is intractable.
  \item So let's learn $\mu, \sigma$ to approximate $P(\theta | D)$ with $q(\theta | \mu, \sigma^2)$, where
    \begin{equation*}
      q(\theta | \mu, \sigma^2) = \mathcal{N}(\mu, \sigma^2) \stackrel{abbrev.}{=} q(\theta)
    \end{equation*}
  \end{itemize}
\end{frame}


